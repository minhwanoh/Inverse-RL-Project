# Inverse RL Project


## MaxEnt IRL
Ziebart et al. The classic Maximum Entropy Inverse RL:<br />
https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf

Wulfmeier et al. MaxEnt IRL with neural net reward function, known dynamics:<br />
http://www.robots.ox.ac.uk/~mobile/Papers/DeepIRL_2015.pdf<br />
Code: https://github.com/stormmax/irl-imitation <br />
      https://github.com/MatthewJA/Inverse-Reinforcement-Learning

Chelsea Finn, et al. ICML ’16 Sampling based method for MaxEnt IRL that handles unknown dynamics and deep reward functions:<br />
https://arxiv.org/pdf/1603.00448.pdf <br />
Code: https://github.com/cbfinn/gps

## Adversarial IRL
Ho & Ermon. NIPS ’16. Generative Adversarial Imitation Learning, Inverse RL method using generative adversarial networks: <br />
https://arxiv.org/pdf/1606.03476.pdf <br />
Code: https://github.com/andrewliao11/gail-tf

Baram et al. ICML ’17. use learned dynamics model to backdrop through discriminator: <br />
http://proceedings.mlr.press/v70/baram17a/baram17a.pdf <br />
Code: https://github.com/itaicaspi/mgail

## Evolution Strategy
Salimans et al. Gradient free. highly parallelizable black box method: : <br />
https://arxiv.org/pdf/1703.03864.pdf


